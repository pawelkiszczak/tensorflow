{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intruduction to NLP fundamentals in TensorFlow\n",
        "NLP has the goal of deriving information out of natural language (could be sequences of text or speech).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)."
      ],
      "metadata": {
        "id": "xmt1b5Fai0yV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for the GPU"
      ],
      "metadata": {
        "id": "PTpVqmF2jR2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hotxq7cjf35",
        "outputId": "018b554a-b66d-4dd6-cbaa-f0b939c89e6c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-537df743-0a99-09e4-59d6-6c6462520ce4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get helper functions"
      ],
      "metadata": {
        "id": "w1R2L85tjivv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the helper functions\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVMUjBgljuZ4",
        "outputId": "e51c70d5-dc83-4b25-b8f6-a6587212a3ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-22 19:12:31--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-22 19:12:31 (86.3 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a text dataset\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labeled as disaster or not disaster).\n",
        "\n",
        "See the orignal source here: https://www.kaggle.com/competitions/nlp-getting-started"
      ],
      "metadata": {
        "id": "Xf-rpsnZkITz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# Unzip data\n",
        "unzip_data('nlp_getting_started.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufwU-YbykYtz",
        "outputId": "03fe7a8b-915d-4adf-cbf8-5f63b127a132"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-22 19:12:39--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.132.128, 74.125.201.128, 74.125.202.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.132.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2023-03-22 19:12:39 (66.5 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Become one with the data - visualize a text dataset\n",
        "\n",
        "To visualize our text sample, we first need to read them in. One way to do so would be to use Python.\n",
        "\n",
        "But we can get visual straight away.\n",
        "\n",
        "So another way to do this is to use Pandas.\n",
        "\n",
        "TF help: https://www.tensorflow.org/tutorials/load_data/text"
      ],
      "metadata": {
        "id": "j9Nu0Ggrk4pK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "wP2XJTFVBeoL",
        "outputId": "0ec6461f-8b37-4b1a-9cbf-f54c1969e674"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7cb320b-eddf-4c7f-9fa4-739c7111c5f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7cb320b-eddf-4c7f-9fa4-739c7111c5f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7cb320b-eddf-4c7f-9fa4-739c7111c5f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7cb320b-eddf-4c7f-9fa4-739c7111c5f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['text'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "e7_rMIsICN7b",
        "outputId": "0719d3f3-de08-40a7-9ace-0239907f6977"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['text'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "QKkTZQMMCXIL",
        "outputId": "a9780742-39cf-40ec-b618-4f8ba62e27e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Forest fire near La Ronge Sask. Canada'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, \n",
        "                                    random_state=42)\n",
        "\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "6SewtWszCayu",
        "outputId": "8012c8c9-acc7-47f3-8083-46fad94d4b5d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-101f713f-3163-4cf8-82fd-394a889eb889\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-101f713f-3163-4cf8-82fd-394a889eb889')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-101f713f-3163-4cf8-82fd-394a889eb889 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-101f713f-3163-4cf8-82fd-394a889eb889');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What does the test dataset look like?\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "Li4LSzDlCxc5",
        "outputId": "f51eae92-48f5-4acc-e906-825d4a280e09"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bb05696-6c67-4215-a82b-451eb9d09680\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bb05696-6c67-4215-a82b-451eb9d09680')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7bb05696-6c67-4215-a82b-451eb9d09680 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7bb05696-6c67-4215-a82b-451eb9d09680');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples are there?\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzXxvR9qC6V5",
        "outputId": "db7cc544-0668-4523-933d-fa711d6c4071"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If dataset is imbalanced: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
      ],
      "metadata": {
        "id": "0KuHKiNsDF70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many total samples\n",
        "len(train_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYOydh_kD2dl",
        "outputId": "02641c7c-1419-43a1-ad29-3bba22eb565f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random training examples\n",
        "import random \n",
        "random_index = random.randint(0, len(train_df)-5) #create random indexes not higher then random number of samples\n",
        "\n",
        "for row in train_df_shuffled[['text', 'target']][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text: \\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CLQTQ5pD52C",
        "outputId": "9f4dbf2d-0acd-46e0-d293-a84199edcc20"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text: \n",
            "http://t.co/iNkuv5DNTX #auction #shoes Retro 5 fire red http://t.co/1cvEGTIZOG\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text: \n",
            "Islamic State claims suicide bombing at Saudi Arabian mosque: Ten members of emergency service... http://t.co/mpOaEFQl6k via @josephjett\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text: \n",
            "The sign-up is open for the FALLING FOR DANGER release day blast and review tour. Sign-up here:... http://t.co/hbdo22nqPZ\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text: \n",
            "@TheBlackshag @dannyoneil too toxic...cancer....disease...hazardous waste...noxious...\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text: \n",
            "@michelleellle ?? shut up freshman its past ur curfew. u need some sleep!! u spend too much of ur time watching tv instead of going outside ??\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data into training and validation sets"
      ],
      "metadata": {
        "id": "b8iETD0bFOYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "49qvM_LJGFXo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use train_test_split to split the training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled['text'],\n",
        "                                                                            train_df_shuffled['target'],\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)"
      ],
      "metadata": {
        "id": "oL6szmWdGSp3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lenghts\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaVpJOWNGx-J",
        "outputId": "88af6077-7749-426b-a76e-fe30d045b5ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check some top samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6d-H_tTIeTi",
        "outputId": "1f696e94-7730-47b5-f836-6fefc1de384c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5921    @mogacola @zamtriossu i screamed after hitting...\n",
              " 3904              Imagine getting flattened by Kurt Zouma\n",
              " 2804    @Gurmeetramrahim #MSGDoing111WelfareWorks Gree...\n",
              " 3718    @shakjn @C7 @Magnums im shaking in fear he's g...\n",
              " 1667    Somehow find you and I collide http://t.co/Ee8...\n",
              " 4435    @EvaHanderek @MarleyKnysh great times until th...\n",
              " 2544                     destroy the free fandom honestly\n",
              " 7223    Weapons stolen from National Guard Armory in N...\n",
              " 4265    @wfaaweather Pete when will the heat wave pass...\n",
              " 6568    Patient-reported outcomes in long-term survivo...\n",
              " Name: text, dtype: object, 5921    0\n",
              " 3904    0\n",
              " 2804    1\n",
              " 3718    0\n",
              " 1667    0\n",
              " 4435    1\n",
              " 2544    1\n",
              " 7223    0\n",
              " 4265    1\n",
              " 6568    1\n",
              " Name: target, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text into numbers.\n",
        "\n",
        "There are a few ways to do this, namely:\n",
        "* Tokenization - direct mapping of token (a token could be a word or a character) to number\n",
        "* Embeddings - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embeddings can be learned)"
      ],
      "metadata": {
        "id": "z45h9HosIjuZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text vectorizaton - tokenization"
      ],
      "metadata": {
        "id": "XnN1A_gCm9Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I50XizlgnAws",
        "outputId": "76e7c41b-f6ea-4b3e-cf4a-577600a3ffd9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5921    @mogacola @zamtriossu i screamed after hitting...\n",
              "3904              Imagine getting flattened by Kurt Zouma\n",
              "2804    @Gurmeetramrahim #MSGDoing111WelfareWorks Gree...\n",
              "3718    @shakjn @C7 @Magnums im shaking in fear he's g...\n",
              "1667    Somehow find you and I collide http://t.co/Ee8...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "metadata": {
        "id": "iyQEYpRwnDwU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (automaticall add <OOV>)\n",
        "                                    standardize='lower_and_strip_punctuation',\n",
        "                                    split='whitespace',\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode='int', # how to map tokens to numbers\n",
        "                                    output_sequence_length=None, # how long you want your sequences to be\n",
        "                                    #pad_to_max_tokens=True\n",
        "                                    )"
      ],
      "metadata": {
        "id": "o3yDkjWrnLdj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ru0OCkBsiUC",
        "outputId": "853e0510-9417-42d0-d287-0516abcbf7a1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words in vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. for many words will a model see)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "F5gCocfhtG_J"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vextorizer to the training set\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "k6ToWSsht3ti"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "malWqurgx6dH",
        "outputId": "6add2eb6-31dc-48e8-fda8-cf8c25f69199"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "      \\n\\nVectorized version: \")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W6dUy3CyHUj",
        "outputId": "f8a70da3-27dd-4b4c-ae01-d69af76faddb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " @BenKin97 @Mili_5499 remember when u were up like 4-0 and blew it in one game? U probs don't because it was before the kings won the cup      \n",
            "\n",
            "Vectorized version: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[  1,   1, 594,  45, 142,  67,  27,  25, 354,   7, 555,  15,   4,\n",
              "         61, 397]])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in training data\n",
        "top_5_words = words_in_vocab[:5] # most 5 common words\n",
        "bottom_5_words = words_in_vocab[-5:]\n",
        "\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words are: {top_5_words}\")\n",
        "print(f\"Top 5 least common words are: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKf7TOzHytZv",
        "outputId": "d0d3c62e-22a2-4f3f-d8bf-7bb5f3a4df0f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words are: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Top 5 least common words are: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and Embedding using and Embedding Layer\n",
        "To make our embedding we're going to use TensorFlow's Embedding Layer.\n",
        "\n",
        "Parameters we care the most are:\n",
        "* `input_dim` = the size of our vocabulary\n",
        "* `output_dim` = the size of the output embedding vector, for example: a value of 100 would mean each token gets represented by a vector 100 long\n",
        "* `input_length` = length of sequences being passes to the embedding layer"
      ],
      "metadata": {
        "id": "F402cRDjzVCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # output shape\n",
        "                             input_length=max_length #how long in each input\n",
        "                             )\n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ8urmtcez--",
        "outputId": "faae4497-d0b1-4171-ef9f-db65fda545c8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7f741829baf0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get another random sentence\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text: {random_sentence}\")\n",
        "print(f\"Embedded version: \")\n",
        "\n",
        "# Embed the random sentence (turn it into the dense vector of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4NG71isfOyY",
        "outputId": "5b2d8f2c-89d9-4edc-874b-1a4714fa07bf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: Well so much for outdoor postering @calgaryfringe #mothernature #hailstorm #rain #yycfringe #KILLHARD\n",
            "Embedded version: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-3.79151106e-03, -8.47990438e-03, -1.23155005e-02, ...,\n",
              "          3.46574225e-02, -1.87554844e-02,  1.74659491e-03],\n",
              "        [-3.44484672e-02, -4.17119041e-02,  2.59278305e-02, ...,\n",
              "          1.71197541e-02,  3.59235294e-02, -2.20036861e-02],\n",
              "        [ 2.88693048e-02, -1.76449791e-02,  2.90600993e-02, ...,\n",
              "          4.68134619e-02,  4.97085191e-02, -1.25393979e-02],\n",
              "        ...,\n",
              "        [-9.18686390e-04,  3.52784991e-06,  2.76698917e-03, ...,\n",
              "          9.31248814e-03, -2.86061764e-02, -2.28958130e-02],\n",
              "        [-9.18686390e-04,  3.52784991e-06,  2.76698917e-03, ...,\n",
              "          9.31248814e-03, -2.86061764e-02, -2.28958130e-02],\n",
              "        [-9.18686390e-04,  3.52784991e-06,  2.76698917e-03, ...,\n",
              "          9.31248814e-03, -2.86061764e-02, -2.28958130e-02]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgIZGA8BfvOO",
        "outputId": "4f4e7e2c-af62-41cf-fd40-35db2a307694"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-3.79151106e-03, -8.47990438e-03, -1.23155005e-02,  4.72400226e-02,\n",
              "         3.74482907e-02, -8.03745911e-03, -2.94770133e-02, -3.35872062e-02,\n",
              "        -4.91266511e-02, -3.55492830e-02,  1.18766427e-02, -1.88810583e-02,\n",
              "         6.85504824e-03, -4.30230610e-02,  9.04492289e-03,  2.25400664e-02,\n",
              "         2.21837275e-02,  1.01812854e-02, -4.79272977e-02, -2.63975020e-02,\n",
              "        -3.93969417e-02, -4.19388898e-02, -9.73069668e-03,  3.24008204e-02,\n",
              "        -2.44721025e-03, -7.47387484e-03, -4.20062654e-02, -4.82944138e-02,\n",
              "        -8.57419893e-03,  4.37496938e-02,  6.78550452e-04,  1.85780190e-02,\n",
              "         1.52916200e-02,  7.89176300e-03,  4.58773226e-03, -2.99355630e-02,\n",
              "        -9.32936743e-03, -1.90593842e-02, -1.31447203e-02,  8.02614540e-03,\n",
              "         3.92881669e-02, -4.09743898e-02,  2.34518759e-02, -4.54181693e-02,\n",
              "         2.56788172e-02,  3.31434943e-02,  2.98328511e-02,  3.62524651e-02,\n",
              "         6.94258139e-03,  3.10071222e-02,  4.29478623e-02, -1.00374930e-02,\n",
              "         4.80543859e-02,  2.70137526e-02, -3.54748592e-02, -1.05488785e-02,\n",
              "        -7.05942512e-05,  2.99815424e-02,  2.24671699e-02, -2.48752236e-02,\n",
              "         4.83198278e-02, -3.44879143e-02, -1.60948634e-02, -2.67715808e-02,\n",
              "         4.46824916e-02, -3.48590314e-04, -2.86178831e-02,  1.69603117e-02,\n",
              "         3.22750956e-03,  1.54933371e-02,  3.04941274e-02,  1.09519586e-02,\n",
              "         3.40387262e-02,  3.16767134e-02,  2.89738886e-02,  1.12716928e-02,\n",
              "         4.36701663e-02,  5.04754856e-03,  3.07013653e-02, -4.30005901e-02,\n",
              "        -1.13533363e-02, -1.61095746e-02,  4.06675078e-02, -3.66525725e-03,\n",
              "         2.94734724e-02, -6.29805028e-04, -2.60798931e-02,  3.34648527e-02,\n",
              "        -2.49656439e-02, -2.58236527e-02, -4.55464981e-02,  3.96845601e-02,\n",
              "         4.95280884e-02, -4.77757826e-02,  2.68078931e-02, -4.78086956e-02,\n",
              "         2.38363035e-02, -1.57712698e-02,  4.38157655e-02,  2.79276110e-02,\n",
              "        -2.03762297e-02, -4.43247557e-02, -4.36251163e-02,  3.00010182e-02,\n",
              "         3.25827263e-02,  2.89125480e-02,  3.61786373e-02,  4.77191061e-03,\n",
              "         3.28108929e-02,  4.38097604e-02,  1.43398531e-02, -3.97228114e-02,\n",
              "         2.50972435e-03,  2.79216878e-02, -3.16120759e-02, -3.58143933e-02,\n",
              "        -3.43627557e-02,  3.58226411e-02, -2.79272720e-03,  2.67715938e-02,\n",
              "         1.41811371e-03,  6.21704012e-03,  4.64095734e-02,  3.26295383e-02,\n",
              "         4.76892330e-02,  3.46574225e-02, -1.87554844e-02,  1.74659491e-03],\n",
              "       dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'Well so much for outdoor postering @calgaryfringe #mothernature #hailstorm #rain #yycfringe #KILLHARD')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling a text dataset (running a bunch of experiments)\n",
        "\n",
        "Now we've got a way to turn our text sequences into numbers, it's time to start building a series of modelling experiments.\n",
        "\n",
        "We'll start with a baseline and move on from there.\n",
        "\n",
        "* Model 0: Naive Bayes (baseline), this is from Sklearn ML Map\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM Model (RNN)\n",
        "* Model 3: GRU Model (RNN)\n",
        "* Model 4: Bidirectional-LSTM (RNN)\n",
        "* Model 5: 1D Convolutional Neural Network (CNN)\n",
        "* Model 6: TensorFlow Hub Pretrained feature Extractor (using transfer learning for NLP)\n",
        "* Model 7: Same as model 6, but with 10% training data"
      ],
      "metadata": {
        "id": "dgJvJgXwgUhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0: getting a baseline\n",
        "\n",
        "As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiments to build upon. \n",
        "\n",
        "To create our baseline, we'll use Sklearn's Multinomial Naive Bayes using the TF-IDF formula to convert our words to numbers.\n",
        "\n",
        "> **NOTE:** It's common practice to use non-DL algorythms as a baseline model because of their speed and then later using DL to see if you can improve upon them.\n"
      ],
      "metadata": {
        "id": "BhI9c2klinko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()), # convert words to numbers using TF-IDF\n",
        "    ('clf', MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "-m9dKwx0kQGp",
        "outputId": "850eaf49-dd6e-40e0-82e4-23eb1a0437d8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMXBI1pglDuE",
        "outputId": "e433f9dd-3115-4c88-c987-80ca23e2e77b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions \n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENyZc916lbYI",
        "outputId": "ee73cc28-b99b-4a3b-84f8-8f624a501ff2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "We could evaluate all of our model's predictions with different metrics every time. However this may bu cumbersom and will surely take some time.\n",
        "\n",
        "Let's create one to compare our model's predcitions with truth labels using the following metrics:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ],
      "metadata": {
        "id": "K2NAvMtnlpn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, recall, precision, f1-score\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculate model accuracy, recall, precision and f1-score of a binary classification model.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "\n",
        "  # Calculate precision, recall and f1-score using 'weighted' metrics\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "\n",
        "  model_results = {'accuracy': model_accuracy,\n",
        "                   'precision': model_precision,\n",
        "                   'recall': model_recall,\n",
        "                   'f1': model_f1}\n",
        "\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "t7VeGQHOu93D"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1KPAleRwhqU",
        "outputId": "b661e869-0079-4855-e23d-dc582bdaf3c7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: A simple dense model"
      ],
      "metadata": {
        "id": "9APo8BNdwvz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensorboard callback (need to create new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "UcVJ94Y2xrDB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with Functional API\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to each vector\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x) # create the output layer, want binary output so sigmoid\n",
        "\n",
        "model_1 = tf.keras.Model(inputs, outputs, name='model_1_dense')"
      ],
      "metadata": {
        "id": "zPQxj8C9x80c"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLvAxQrHyrL_",
        "outputId": "93d69a21-1215-4fdb-f3b4-2d5671cfb474"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model_1.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5ZpFk9NRysUN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name='model_1_dense')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7Lo04cCzFW6",
        "outputId": "c1483887-b769-413a-f3cd-64d64a7074a6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20230322-191248\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 17s 53ms/step - loss: 0.6125 - accuracy: 0.6930 - val_loss: 0.5352 - val_accuracy: 0.7625\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.4432 - accuracy: 0.8180 - val_loss: 0.4675 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3488 - accuracy: 0.8606 - val_loss: 0.4568 - val_accuracy: 0.7913\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.2854 - accuracy: 0.8891 - val_loss: 0.4645 - val_accuracy: 0.7887\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.2381 - accuracy: 0.9111 - val_loss: 0.4809 - val_accuracy: 0.7808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHFPpDQazd7v",
        "outputId": "419524ed-8635-43d3-a737-0f247c39a385"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7808\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4808727204799652, 0.7808399200439453]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ygcn91nzpYX",
        "outputId": "d06a083e-5604-4e4e-84ff-6f788b21d5ea"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.32402468],\n",
              "       [0.7305316 ],\n",
              "       [0.99711347],\n",
              "       [0.14024135],\n",
              "       [0.09704939],\n",
              "       [0.93447226],\n",
              "       [0.90929466],\n",
              "       [0.99207   ],\n",
              "       [0.96043587],\n",
              "       [0.31167376]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Single prediction\n",
        "model_1_pred_probs[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYO9vda6zy4I",
        "outputId": "7655d70d-d088-489e-fb2c-5160a31793c6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.7305316], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gCIU1631Umy",
        "outputId": "8eecfc00-6a7b-42f8-fd9e-773dceff4098"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEC43_Di1oIN",
        "outputId": "c533fb60-6a2c-4eae-84f1-cd59472e7c30"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'precision': 0.7848699684611963,\n",
              " 'recall': 0.7808398950131233,\n",
              " 'f1': 0.7779792730264676}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values()))> np.array(list(baseline_results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ__Zsaa12UV",
        "outputId": "485b3ff9-1fe7-4a74-ad98-4ef31128ede4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing learned embeddings"
      ],
      "metadata": {
        "id": "02ffs-Uh2CY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv85xsbnck5o",
        "outputId": "f698267c-3d32-4e38-b1c4-fc182983f8d5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model_1 summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp7FJ-cMcrSn",
        "outputId": "1fe72254-bf38-40b1-cf2a-ad0b4d6331ca"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# (these are the numerical representation of each token in our training data\n",
        "# which have been learned for 5 epochs)\n",
        "embed_weights = model_1.get_layer('embedding').get_weights()[0]\n",
        "embed_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI-BYC5Vc7N0",
        "outputId": "ddfa30ff-80fc-4b74-a482-629d788be5a5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.0165341 , -0.01156985,  0.01828641, ..., -0.00566531,\n",
              "        -0.0164663 , -0.03809671],\n",
              "       [-0.06167642,  0.03693729, -0.02772405, ..., -0.04792374,\n",
              "        -0.01465564, -0.05094279],\n",
              "       [-0.04264189, -0.03407058, -0.02361921, ...,  0.0345754 ,\n",
              "        -0.02575861,  0.02730376],\n",
              "       ...,\n",
              "       [-0.02529265,  0.00396367, -0.01636482, ...,  0.02642414,\n",
              "         0.02134185, -0.01224426],\n",
              "       [-0.02269838, -0.06684919,  0.01318339, ..., -0.06196566,\n",
              "         0.0051993 , -0.00876852],\n",
              "       [-0.0658977 , -0.02980096,  0.08537647, ..., -0.05522868,\n",
              "         0.11287592, -0.01355842]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_weights.shape # same size as vocab size and embedding_dim (output_dim of our embedding layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLjCOQCKdMsZ",
        "outputId": "1c8d3ce0-b173-4781-fc87-348a8c8bca48"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got the embedding matrix, our model has learned to represent our tokens. Let's see how we can visualize it.\n",
        "\n",
        "To do so, TensorFlow has a handy tool called projector: http://projector.tensorflow.org/\n",
        "\n",
        "And TensorFlow also has an incredible guide on word embeddings themselves."
      ],
      "metadata": {
        "id": "cIk-oRMXd-O0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code straight from TensorFlow documentation\n",
        "# Create embedding files\n",
        "import io\n",
        "\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "Yo27tSjVdoZl"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download files from Colab to import them to Projector\n",
        "# Code straight from TensorFlow documentation\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "tyyonNDHfP93",
        "outputId": "63c76db6-613d-4a8c-d112-415716bec888"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d4cc8e65-f448-40ee-9ddd-ab57dc03af42\", \"vectors.tsv\", 15381263)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_17f56442-0081-460d-8d25-76273d3f7edf\", \"metadata.tsv\", 80388)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNN's are useful for sequential data.\n",
        "\n",
        "The premise of a recurrent neural network is to use the representation of a precious input to aid the representation of a later input."
      ],
      "metadata": {
        "id": "KDjEwMFjgOJj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM = Long short term memory (one of the most popular RNN cells).\n",
        "\n",
        "Our structure of an RNN typically looks like this:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNNs/Dense) -> Output (label probability)\n",
        "\n"
      ],
      "metadata": {
        "id": "B1elmwWxif63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an LSTM model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#print(x.shape)\n",
        "#x = layers.LSTM(units=64, return_sequences=True)(x) # when you're stacking RNN cells together, you need to return_sequences=True\n",
        "#print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "#print(x.shape)\n",
        "#x = layers.Dense(64, activation='relu')(x)\n",
        "#print(x.shape)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, outputs, name='model_2_LSTM')"
      ],
      "metadata": {
        "id": "3wwkFTR-pPZJ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbtRF0Fzqcxa",
        "outputId": "746345a3-9379-45b4-8f2b-114a1acc2dec"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gXF3lddDsPxh"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     'model_2_LSTM')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgbYhMvYsbiA",
        "outputId": "2cbada59-3f61-49bf-b8c0-dbbb9bfd7863"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230322-191333\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 14s 48ms/step - loss: 0.2267 - accuracy: 0.9215 - val_loss: 0.5301 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1575 - accuracy: 0.9419 - val_loss: 0.6456 - val_accuracy: 0.7677\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1286 - accuracy: 0.9514 - val_loss: 0.6919 - val_accuracy: 0.7835\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1084 - accuracy: 0.9594 - val_loss: 0.8301 - val_accuracy: 0.7769\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.0894 - accuracy: 0.9650 - val_loss: 0.8586 - val_accuracy: 0.7743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnOANjSksweY",
        "outputId": "45ee4856-df67-4f80-a994-be435d60839d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.6782122e-02],\n",
              "       [6.0469967e-01],\n",
              "       [9.9960083e-01],\n",
              "       [1.1015288e-01],\n",
              "       [4.0242885e-04],\n",
              "       [9.9543238e-01],\n",
              "       [8.7401116e-01],\n",
              "       [9.9967003e-01],\n",
              "       [9.9945503e-01],\n",
              "       [6.4194614e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model_2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJEy86gjs6Nq",
        "outputId": "52fe2a75-6754-4b02-dab2-57dc0fd30ea5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlNgMRFqtHUl",
        "outputId": "6e7de556-e2f9-4f75-fdc6-c63c2f46efc1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.42782152230971,\n",
              " 'precision': 0.7752857985262857,\n",
              " 'recall': 0.7742782152230971,\n",
              " 'f1': 0.7725974162749719}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvEyirUitQ_G",
        "outputId": "ce9c1dca-dc68-4c09-cc0d-97528c040587"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: GRU\n",
        "Another popular and effective RNN component is the GRU layer (or Gated Recurrent Unit).\n",
        "\n",
        "The GRU cell has similar features to LSTM cell but has less parameters."
      ],
      "metadata": {
        "id": "WMw4fcKepcWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#x = layers.GRU(64, return_sequences=True)(x) # return_sequences=True if stacking layers\n",
        "#x = layers.LSTM(64, return_sequences=True)(x)\n",
        "#x = layers.GRU(64)(x)\n",
        "#x = layers.Dense(64, activation='relu')(x)\n",
        "#x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.GRU(64)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs, outputs, name='model_3_GRU')"
      ],
      "metadata": {
        "id": "1W4_EZF-pzNw"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the summary\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdcvJB9brzhm",
        "outputId": "27e58740-87d5-4de8-cc39-46948f4a36ff"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ew5yPOADsX_t"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_3_GRU')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcd2442CtheP",
        "outputId": "ea1bb597-c5a2-4d12-8a4c-697fe30c04b9"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20230322-191356\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 37ms/step - loss: 0.1594 - accuracy: 0.9356 - val_loss: 0.7415 - val_accuracy: 0.7743\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0802 - accuracy: 0.9695 - val_loss: 0.7875 - val_accuracy: 0.7769\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.0704 - accuracy: 0.9734 - val_loss: 0.8739 - val_accuracy: 0.7730\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0616 - accuracy: 0.9759 - val_loss: 1.0506 - val_accuracy: 0.7743\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0508 - accuracy: 0.9787 - val_loss: 1.2976 - val_accuracy: 0.7690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlCki5l9tzpU",
        "outputId": "1175d709-0db9-4879-ee11-a22ea75def73"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.9183676e-04],\n",
              "       [8.0372691e-01],\n",
              "       [9.9981517e-01],\n",
              "       [5.0000466e-02],\n",
              "       [4.9625487e-05],\n",
              "       [9.9962246e-01],\n",
              "       [7.8384084e-01],\n",
              "       [9.9995506e-01],\n",
              "       [9.9987686e-01],\n",
              "       [9.2680556e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzXJuV3wt62I",
        "outputId": "95768b7f-4747-4170-ea35-2d1f17a37eb9"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C564TPh6uG40",
        "outputId": "72669573-0fb6-40c9-a12e-e38fcfbd4409"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'precision': 0.7731540113429877,\n",
              " 'recall': 0.7690288713910761,\n",
              " 'f1': 0.7657803921853192}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "Normal RNNs go from left to right (just the same way you read an English sentence). However, bidirectional RNN goes from right to left as well as from left to right."
      ],
      "metadata": {
        "id": "i5Aqo4ZuuP25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bidirectional RNN model 4\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_4 = tf.keras.Model(inputs, outputs, name='model_4_bidirectional')"
      ],
      "metadata": {
        "id": "S35DCqeOu2_I"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the summary\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExYOXWgevgyG",
        "outputId": "7cfa66b3-d4c9-4ab4-c1eb-3140aef9615c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_4.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WBAX4uyJv8B4"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_4_bidirectional')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gNBZ7PJwG83",
        "outputId": "1401a781-b469-4d7b-aadd-5a7983c8a0cd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20230322-191416\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 14s 44ms/step - loss: 0.1049 - accuracy: 0.9660 - val_loss: 0.9885 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0537 - accuracy: 0.9777 - val_loss: 1.1291 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0451 - accuracy: 0.9803 - val_loss: 1.2522 - val_accuracy: 0.7664\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0411 - accuracy: 0.9801 - val_loss: 1.2665 - val_accuracy: 0.7598\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.0439 - accuracy: 0.9812 - val_loss: 1.1781 - val_accuracy: 0.7730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predicitons\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzDa0pNpzC7O",
        "outputId": "5f38d8a1-070b-4ed7-ffaf-5a71b1e3cf93"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.7189220e-03],\n",
              "       [7.2863185e-01],\n",
              "       [9.9988735e-01],\n",
              "       [1.4180492e-01],\n",
              "       [1.0002956e-04],\n",
              "       [9.9536419e-01],\n",
              "       [6.9474512e-01],\n",
              "       [9.9993443e-01],\n",
              "       [9.9987376e-01],\n",
              "       [7.4568182e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predictions\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBRtEdqezSKe",
        "outputId": "287f3ac2-c77d-45b3-8672-c116d2204d98"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFrG9T_2zbvs",
        "outputId": "4114ee6e-c4bb-4448-d219-77eb16f574c0"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.29658792650919,\n",
              " 'precision': 0.7766832892495897,\n",
              " 'recall': 0.7729658792650919,\n",
              " 'f1': 0.7700024804405922}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Networks for Text (and other sequences)\n",
        "\n",
        "We've used CNNs for images, but images are typically 1D (H x W), however our text data is 1D.\n",
        "\n",
        "Previoulsy we've used `Conv2D()` for image data but now we're going to use `Conv1D()` as data is 1-dimensional.\n",
        "\n",
        "The typical structure of a Conv1D model for sequences (in our case, text):\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + pooling) -> Outputs\n",
        "```"
      ],
      "metadata": {
        "id": "HJPZQFTT094J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5: 1D Convolutional Neural Network"
      ],
      "metadata": {
        "id": "EI0vcy0JzoYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out our embedding layer, Conv1D layer and MaxPooling\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_test = embedding(text_vectorizer(['this is a test sequence'])) # turn target sequence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5, # also referred as an ngram=5 (looks at 5 words at a time)\n",
        "                        strides=1, # default\n",
        "                        activation='relu',\n",
        "                        padding='same') # default = valid, output is smaller than input, same -> input is same shape as output\n",
        "conv_1d_output = conv_1d(embedding_test) # pass embedding through Conv1D layer\n",
        "max_pool = layers.GlobalMaxPooling1D()\n",
        "max_pool_output = max_pool(conv_1d_output) # equaivalent to 'get the most important feature/feature with the highest value'\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xJiuAST3GAs",
        "outputId": "7a8548ca-720d-4325-a074-e216c8d2176b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 15, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#embedding_test"
      ],
      "metadata": {
        "id": "hjv-weBr4kZi"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conv_1d_output"
      ],
      "metadata": {
        "id": "snrWKl4_6pSX"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#max_pool_output"
      ],
      "metadata": {
        "id": "Xt4JIBQF6tMi"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64,\n",
        "                  kernel_size=5,\n",
        "                  activation='relu',\n",
        "                  padding='valid',\n",
        "                  strides=1)(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs, outputs, name='model_5_Conv1D')\n",
        "\n",
        "# Compile Conv1D\n",
        "model_5.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkLFoGJ26-2V",
        "outputId": "8b194f48-08dd-4f78-d2de-539b7141eeed"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_5_Conv1D')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0TYVQ1kxAx6",
        "outputId": "6a56b084-fb79-4a72-9f9f-421d7351a4c6"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5_Conv1D/20230322-192738\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 40ms/step - loss: 0.0809 - accuracy: 0.9768 - val_loss: 1.0679 - val_accuracy: 0.7572\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0486 - accuracy: 0.9813 - val_loss: 1.1331 - val_accuracy: 0.7546\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0448 - accuracy: 0.9807 - val_loss: 1.2385 - val_accuracy: 0.7480\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0440 - accuracy: 0.9825 - val_loss: 1.2286 - val_accuracy: 0.7493\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0411 - accuracy: 0.9815 - val_loss: 1.2310 - val_accuracy: 0.7428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyxzGNEPxgm9",
        "outputId": "e41d5067-f2d9-408f-ce71-1b54ed52f40f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.3602845e-02],\n",
              "       [9.6805435e-01],\n",
              "       [9.9997509e-01],\n",
              "       [8.5860863e-02],\n",
              "       [2.1820324e-06],\n",
              "       [9.9792457e-01],\n",
              "       [9.7088796e-01],\n",
              "       [9.9999166e-01],\n",
              "       [9.9999976e-01],\n",
              "       [9.5681852e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predictions\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAB1xEZ6xwLz",
        "outputId": "e8e8db43-05a1-4167-e92b-eff21d92cad4"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the results\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x95mt9jOx6Fv",
        "outputId": "8b1f6700-e1a4-4a74-92fc-ad8f1db5927a"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 74.2782152230971,\n",
              " 'precision': 0.7423147810749008,\n",
              " 'recall': 0.7427821522309711,\n",
              " 'f1': 0.7423631256619239}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 6 - TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "Now we've built some of our own models, let's try and use transfer learning for NLP, specifically using Universal Sentence Encoder (or USE for short)."
      ],
      "metadata": {
        "id": "N1sMwsOnyDcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import tensorflow_hub as hub\n",
        " embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n",
        " embed_samples = embed([sample_sentence, 'When you call the universal sentence encoder on a sentence, it turns it into numbers.'])\n",
        "\n",
        " print(embed_samples[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS47HrDc0E_X",
        "outputId": "509b4dec-8b50-411f-c17e-98e76dee623e"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157028  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
            "  0.02680984  0.05589836 -0.0106873  -0.00597291  0.00639323 -0.01819518\n",
            "  0.00030813  0.09105888  0.05874644 -0.03180628  0.01512474 -0.05162929\n",
            "  0.00991367 -0.06865347 -0.04209306  0.02678981  0.03011006  0.00321069\n",
            " -0.00337973 -0.04787357  0.0226672  -0.00985925 -0.04063613 -0.01292092\n",
            " -0.04666384  0.05630299 -0.03949255  0.00517686  0.02495829 -0.0701444\n",
            "  0.02871508  0.04947684 -0.00633979 -0.08960192  0.02807118 -0.00808364\n",
            " -0.01360602  0.0599865  -0.10361787 -0.05195374  0.00232954 -0.02332531\n",
            " -0.03758105  0.03327728], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmTe2S6a2xHg",
        "outputId": "7f1757c8-1c78-45bc-f75c-10dd5cd6e529"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 512), dtype=float32, numpy=\n",
              "array([[-0.01157028,  0.0248591 ,  0.02878048, ..., -0.00186124,\n",
              "         0.02315826, -0.01485021],\n",
              "       [ 0.03596687, -0.08579469, -0.0115274 , ..., -0.03414334,\n",
              "         0.02816025, -0.00878945]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_samples.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLav_Ao63FED",
        "outputId": "f330e14a-2ed8-4cb1-bd00-324d90cb70b2"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Keras Layer using the USE pretrained layer from TensorFlow Hub\n",
        "sentence_encoder_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4', \n",
        "                                       input_shape=[], \n",
        "                                       dtype=tf.string,\n",
        "                                       trainable=False,\n",
        "                                       name='USE')"
      ],
      "metadata": {
        "id": "yvQV1lht5SOu"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model using Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    #layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid', name='output_layer')\n",
        "], name='model_6_USE')\n",
        "\n",
        "# Compile the model\n",
        "model_6.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzwxhGPR6LNe",
        "outputId": "8d79236c-e417-420e-ce78-185a67280fde"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,863,617\n",
            "Trainable params: 65,793\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the classifier on top of USE pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_6_USE')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSGZrpq84L1J",
        "outputId": "dec67461-65f0-4d95-ebad-eccaa25fa3f4"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_6_USE/20230322-201447\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 15ms/step - loss: 0.4840 - accuracy: 0.7900 - val_loss: 0.4506 - val_accuracy: 0.8058\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.4093 - accuracy: 0.8209 - val_loss: 0.4381 - val_accuracy: 0.8150\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3940 - accuracy: 0.8286 - val_loss: 0.4306 - val_accuracy: 0.8136\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3844 - accuracy: 0.8318 - val_loss: 0.4231 - val_accuracy: 0.8176\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3738 - accuracy: 0.8358 - val_loss: 0.4268 - val_accuracy: 0.8123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predicitons\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX3yifhX7MqZ",
        "outputId": "6e3ebb4a-0019-48b2-c513-1a267e2c93ff"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16229738],\n",
              "       [0.810685  ],\n",
              "       [0.99247277],\n",
              "       [0.21266091],\n",
              "       [0.69216317],\n",
              "       [0.73202914],\n",
              "       [0.9824677 ],\n",
              "       [0.9843313 ],\n",
              "       [0.9436467 ],\n",
              "       [0.07944041]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predicition probs\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkCS-g7Z7d4R",
        "outputId": "f4b93532-0452-4ff7-d8b5-03b1be2c59a5"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcaulate results\n",
        "model_6_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_6_preds)\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TV46xqG7nr6",
        "outputId": "56a211d8-56e1-4bd3-9762-cb293b4256a0"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'precision': 0.8167328378435911,\n",
              " 'recall': 0.8123359580052494,\n",
              " 'f1': 0.8101294251786122}"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iyo_AQgw7ywO",
        "outputId": "53f3b492-bfcd-403d-f8e0-75b1c4d950e6"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ3vqgvt70c1",
        "outputId": "3f71dde4-61b0-44c9-ac90-c474006e544d"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6851"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 7: TF Hub Pretrained USE, but with 10% of training data\n",
        "\n",
        "Transfer learning really helps if you do not have a large dataset. \n",
        "\n",
        "To see how our model performs on a smaller dataset, let's replicate `model_6` except we'll train it on 10% of the data."
      ],
      "metadata": {
        "id": "dlHTKWkZ9lNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NOTE: Making data splits like below creates data leakage (model_7 trained on 10% of the data, outperforms model_6 trained on 100% of the data)\n",
        "## DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET\n",
        "'''\n",
        "# Create subset of 10% of the training data\n",
        "train_10_percent = train_df_shuffled[['text', 'target']].sample(frac=0.1, random_state=42)\n",
        "\n",
        "train_sentences_10_percent = train_10_percent['text'].to_list()\n",
        "train_labels_10_percent = train_10_percent['target'].to_list()\n",
        "\n",
        "len(train_10_percent), len(train_10_percent)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "aqgrejy4DhY6",
        "outputId": "a91386da-5f01-4157-e14e-7b13d67ca3ed"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Create subset of 10% of the training data\\ntrain_10_percent = train_df_shuffled[['text', 'target']].sample(frac=0.1, random_state=42)\\n\\ntrain_sentences_10_percent = train_10_percent['text'].to_list()\\ntrain_labels_10_percent = train_10_percent['target'].to_list()\\n\\nlen(train_10_percent), len(train_10_percent)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a better dataset split (no data leakage)\n",
        "train_10_percent_split = int(0.1*len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
        "len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsGPVm3uK0Oi",
        "outputId": "9688110c-b34a-43b2-fd87-9aa9067b2086"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(685, 685)"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of each label in updated subset\n",
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wylI-QI_LicZ",
        "outputId": "185311ee-94df-4acc-f191-8b8c5bb2c76c"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of targets in our subset data\n",
        "# train_labels_10_percent['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Gs5aTyQFENtJ",
        "outputId": "87c91abb-59f7-4a88-9338-e91f4d1aab6e"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3629\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'target'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-182-9e582f004ac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check the number of targets in our subset data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_labels_10_percent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3631\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3632\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'target'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffled['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03UPUyRWEaH_",
        "outputId": "3171d99b-8267-4e22-ceb8-c987294f8507"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreating model 6\n",
        "model_7 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid', name='output_layer')\n",
        "], name='model_7_USE_10_percent')\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model_7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5hRsMIiEhRe",
        "outputId": "5e4a2c00-8189-414b-bfa2-514c13d75c13"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7_USE_10_percent\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,863,617\n",
            "Trainable params: 65,793\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model on 10% of the dataset\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_7_USE_10_percent_correct_split')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tkHT317FfIP",
        "outputId": "770fc9f9-5113-401e-d23e-cb7b2dc21a95"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_7_USE_10_percent_correct_split/20230322-211900\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 60ms/step - loss: 0.6588 - accuracy: 0.7372 - val_loss: 0.6279 - val_accuracy: 0.7349\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.5628 - accuracy: 0.8073 - val_loss: 0.5609 - val_accuracy: 0.7612\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.4773 - accuracy: 0.8131 - val_loss: 0.5058 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.4224 - accuracy: 0.8321 - val_loss: 0.4875 - val_accuracy: 0.7808\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.3847 - accuracy: 0.8423 - val_loss: 0.4836 - val_accuracy: 0.7782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alternative method - cloning a model**<br>\n",
        "To recreate a model the same as previous, you can use `tf.keras.model.clone_model()` method."
      ],
      "metadata": {
        "id": "ScsJ2nusF3cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model\n",
        "# model_7 = tf.keras.model.clone_model(model_6, name)\n",
        "\n",
        "# Compile the model\n",
        "# model_7.compile(loss='binary_crossentropy',\n",
        "#               optimizer='Adam',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "# model_7.summary()"
      ],
      "metadata": {
        "id": "JlVlhlINGbQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx4jFjz_Hsea",
        "outputId": "74c538be-cbd2-4a3d-fc72-5faab1428f20"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.15781969],\n",
              "       [0.57956934],\n",
              "       [0.95138556],\n",
              "       [0.35519707],\n",
              "       [0.5605337 ],\n",
              "       [0.7180959 ],\n",
              "       [0.934155  ],\n",
              "       [0.8597891 ],\n",
              "       [0.8919702 ],\n",
              "       [0.13854818]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert probs\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFulovnuH0U5",
        "outputId": "9c116d7a-26f5-444d-ace9-5b550828dfea"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the results\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woF4VkodH7mO",
        "outputId": "18cf2024-1063-450a-8994-f1ff3b327020"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.82152230971128,\n",
              " 'precision': 0.7779972615729265,\n",
              " 'recall': 0.7782152230971129,\n",
              " 'f1': 0.7775081589477405}"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN-Y5tFEIC7_",
        "outputId": "af82d829-5f80-4524-95c4-8e2c1e068fc8"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'precision': 0.8167328378435911,\n",
              " 'recall': 0.8123359580052494,\n",
              " 'f1': 0.8101294251786122}"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **NOTE**: Be *very* careful when creating training/val/test splits that you do not leak daa across the datasets, otherwise your model evaluation metrics will be wrong. If something looks too good to be true (a model trained on 10% of data outperforming the same model trained on 100% of the data), trust your gut and go back through to find where the error may lie."
      ],
      "metadata": {
        "id": "OjauVhYlJJpn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bK4Xg2raM8Qr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}