{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1\n",
        "Rebuild , compile and train `model_1`, `model_2` and `model_5` using the `Keras Sequential API` instead of `Functional API`."
      ],
      "metadata": {
        "id": "p3Wd9F5_mAKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the GPU"
      ],
      "metadata": {
        "id": "CPB-jO1qnq4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for the GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRIdOp0asnd4",
        "outputId": "9cf720b3-8662-4bfd-a036-dc7a3b0d29c1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the helper functions"
      ],
      "metadata": {
        "id": "nVqGR_rBssW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the helper functions\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRx_xrTGszcJ",
        "outputId": "f0016d63-6d38-400a-83dc-e62eac6ea26a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-26 19:41:35--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-26 19:41:35 (92.8 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a text dataset"
      ],
      "metadata": {
        "id": "-Qam418Xs3zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# Unzip data\n",
        "unzip_data('nlp_getting_started.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UonJH4N0s7ai",
        "outputId": "1037edd3-5285-463b-b76e-9dcc8d92221a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-26 19:41:39--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 74.125.195.128, 173.194.202.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-03-26 19:41:39 (114 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "957zb8Mitr6O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffling the test dataset\n",
        "train_data_shuffled = train_data.sample(frac=1, random_state=42)\n",
        "train_data_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "YY-gBWsVt5a5",
        "outputId": "b14bb334-e499-4acc-9f3b-a327230e73c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33b1d8c3-c0d8-4a45-9828-6809b24f33f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33b1d8c3-c0d8-4a45-9828-6809b24f33f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33b1d8c3-c0d8-4a45-9828-6809b24f33f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33b1d8c3-c0d8-4a45-9828-6809b24f33f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the data into training/validations sets"
      ],
      "metadata": {
        "id": "pIeZNtMPs82U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_data_shuffled['text'],\n",
        "                                                                            train_data_shuffled['target'],\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)"
      ],
      "metadata": {
        "id": "TtfYyIS2tHeS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths\n",
        "len(train_sentences) == len(train_labels), len(val_sentences) == len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mZaHf41uOwl",
        "outputId": "3b84e35a-33d5-43ee-a44d-d74fe48abc42"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text data into numerical data"
      ],
      "metadata": {
        "id": "RtkzkAR3vNK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization"
      ],
      "metadata": {
        "id": "tg3sVKLtvXvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "metadata": {
        "id": "_pyhUhjJvZD6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the vectorization variables\n",
        "max_vocab_length = 10000\n",
        "max_length = 15"
      ],
      "metadata": {
        "id": "k4y3P3YP0Y6F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the TextVectorization \n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int', \n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "Tu4f3-Ft0r85"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to the training set\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "z5NdUQD324Gz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample set and vectorize it\n",
        "sample_sentence = \"We'd love the aliens to visit us!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzHBnHW7393B",
        "outputId": "92be520f-e401-4cc7-c18c-33db16bd02a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[1924,  110,    2, 6238,    5, 1742,   69,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the vocabulary\n",
        "vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Top 5 most used words: {vocab[:5]}\")\n",
        "print(f\"Top 5 least used words: {vocab[-5:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t665D87r4enf",
        "outputId": "3594298b-91b9-4259-bb5b-2b8d112461fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most used words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Top 5 least used words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding"
      ],
      "metadata": {
        "id": "3UnRIttt46k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create embedding layer\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # input shape\n",
        "                             output_dim=128, # output shape\n",
        "                             input_length=max_length) # input length\n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqpdmfTR5OmP",
        "outputId": "038fecce-ffb4-4e44-a5c9-e86e7018d8e0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7f1d351a5d00>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if it works\n",
        "print(f\"Sample sentence: \\n{sample_sentence}\")\n",
        "print(f\"\\nSample sentence vectorized: \\n{text_vectorizer([sample_sentence])}\")\n",
        "print(f\"\\nSample sentence embedded: \\n{embedding(text_vectorizer([sample_sentence]))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfR0VeYF6ANc",
        "outputId": "b8f2f62d-ddb0-4b26-b379-65c76755c05c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample sentence: \n",
            "We'd love the aliens to visit us!\n",
            "\n",
            "Sample sentence vectorized: \n",
            "[[1924  110    2 6238    5 1742   69    0    0    0    0    0    0    0\n",
            "     0]]\n",
            "\n",
            "Sample sentence embedded: \n",
            "[[[ 0.00788132 -0.04829688 -0.01385916 ...  0.01228603 -0.01670926\n",
            "    0.01227896]\n",
            "  [ 0.04368892 -0.02601178  0.01097583 ... -0.02443379 -0.03107102\n",
            "   -0.01516576]\n",
            "  [ 0.02757699  0.0175313   0.03094289 ... -0.00958041 -0.03032207\n",
            "   -0.0256814 ]\n",
            "  ...\n",
            "  [-0.00117085  0.03885223 -0.03981144 ...  0.03352464  0.02280668\n",
            "   -0.02000021]\n",
            "  [-0.00117085  0.03885223 -0.03981144 ...  0.03352464  0.02280668\n",
            "   -0.02000021]\n",
            "  [-0.00117085  0.03885223 -0.03981144 ...  0.03352464  0.02280668\n",
            "   -0.02000021]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper function to evaluate the models"
      ],
      "metadata": {
        "id": "57ZxoBB97Nv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  # Calculate model accuracy\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "  # Calculate precision, recall and f1-score (in 'weighted' mode)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(y_true,\n",
        "                                                             y_pred,\n",
        "                                                             average='weighted')\n",
        "  \n",
        "  results = {'accuracy': accuracy,\n",
        "             'precision': precision,\n",
        "             'recall': recall,\n",
        "             'f1-score': f1}\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "psuHGEWd7dy0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorBoard callback\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "SAVE_DIR = 'exercise_model_logs'"
      ],
      "metadata": {
        "id": "JrlU0XVPANjZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 reproduction - simple dense model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Te2aZ5P48o89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model with Sequential API\n",
        "model_1 = tf.keras.Sequential([\n",
        "    layers.Input(shape=(1,), dtype=tf.string),\n",
        "    text_vectorizer,\n",
        "    embedding,\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "], name='model_1_dense')\n",
        "\n",
        "model_1.summary()\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FkG1uLe88d5",
        "outputId": "6faefa36-4b68-4f86-e1e5-31ff89e101bd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model \n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                    'model_1_dense_Sequential')],\n",
        "                              verbose=2)"
      ],
      "metadata": {
        "id": "rLXG6Vvm-UJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec2bf1d1-c64a-4d78-defe-c5ee3ce32336"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: exercise_model_logs/model_1_dense_Sequential/20230326-194142\n",
            "Epoch 1/5\n",
            "215/215 - 5s - loss: 0.6115 - accuracy: 0.6892 - val_loss: 0.5379 - val_accuracy: 0.7467 - 5s/epoch - 25ms/step\n",
            "Epoch 2/5\n",
            "215/215 - 3s - loss: 0.4423 - accuracy: 0.8206 - val_loss: 0.4727 - val_accuracy: 0.7848 - 3s/epoch - 14ms/step\n",
            "Epoch 3/5\n",
            "215/215 - 2s - loss: 0.3474 - accuracy: 0.8612 - val_loss: 0.4574 - val_accuracy: 0.7927 - 2s/epoch - 11ms/step\n",
            "Epoch 4/5\n",
            "215/215 - 2s - loss: 0.2846 - accuracy: 0.8905 - val_loss: 0.4688 - val_accuracy: 0.7940 - 2s/epoch - 11ms/step\n",
            "Epoch 5/5\n",
            "215/215 - 2s - loss: 0.2377 - accuracy: 0.9104 - val_loss: 0.4806 - val_accuracy: 0.7808 - 2s/epoch - 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate and predict\n",
        "def evaluate_and_pred(model, data_to_predict, labels_to_predict):\n",
        "  \"\"\"\n",
        "  Evaluates on data_to_predict and returns predictions as 1 or 0.\n",
        "  \"\"\"\n",
        "\n",
        "  # Evaluate the model\n",
        "  eval = model.evaluate(data_to_predict, labels_to_predict)\n",
        "  print(f\"Evaluation metrics: {eval}\\n\")\n",
        "\n",
        "  # Get the predictions \n",
        "  pred_probs = model.predict(data_to_predict)\n",
        "  preds = tf.squeeze(tf.round(pred_probs))\n",
        "\n",
        "  print(f\"Preds overview: {preds[:10]}\")\n",
        "\n",
        "  return preds"
      ],
      "metadata": {
        "id": "iRTF0JCPGb21"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation and preds\n",
        "model_1_preds = evaluate_and_pred(model_1, val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW9jv6z5wREK",
        "outputId": "d0fc4157-fb19-4fd2-c4da-3371b07453f3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7808\n",
            "Evaluation metrics: [0.4805794954299927, 0.7808399200439453]\n",
            "\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "Preds overview: [0. 1. 1. 0. 0. 1. 1. 1. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the results\n",
        "model_1_results = calculate_results(val_labels, model_1_preds)\n",
        "model_1_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfknwHCRwbvg",
        "outputId": "922a3771-ec05-494b-ac8c-ff9073571767"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7808398950131233,\n",
              " 'precision': 0.7809067257781027,\n",
              " 'recall': 0.7808398950131233,\n",
              " 'f1-score': 0.7798778043941109}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2 - LSTM"
      ],
      "metadata": {
        "id": "fsthelTlcWWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "    layers.Input(shape=(1,), dtype=tf.string),\n",
        "    text_vectorizer,\n",
        "    embedding,\n",
        "    layers.LSTM(units=64),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "], name='model_2_lstm')\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Check the summary\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9XOUCG4cvgH",
        "outputId": "cdec62a9-f748-4611-f2d9-dfaaad9e7167"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_lstm\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_2_lstm')],\n",
        "                              verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UPhS3BodaFI",
        "outputId": "5b8fb6c8-630c-45f6-d532-5d244522208a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: exercise_model_logs/model_2_lstm/20230326-194835\n",
            "Epoch 1/5\n",
            "215/215 - 7s - loss: 0.2257 - accuracy: 0.9219 - val_loss: 0.5779 - val_accuracy: 0.7769 - 7s/epoch - 31ms/step\n",
            "Epoch 2/5\n",
            "215/215 - 4s - loss: 0.1572 - accuracy: 0.9415 - val_loss: 0.6731 - val_accuracy: 0.7835 - 4s/epoch - 17ms/step\n",
            "Epoch 3/5\n",
            "215/215 - 4s - loss: 0.1317 - accuracy: 0.9514 - val_loss: 0.6542 - val_accuracy: 0.7848 - 4s/epoch - 16ms/step\n",
            "Epoch 4/5\n",
            "215/215 - 4s - loss: 0.1062 - accuracy: 0.9588 - val_loss: 0.8094 - val_accuracy: 0.7769 - 4s/epoch - 18ms/step\n",
            "Epoch 5/5\n",
            "215/215 - 3s - loss: 0.0864 - accuracy: 0.9672 - val_loss: 0.8007 - val_accuracy: 0.7743 - 3s/epoch - 16ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate and predict\n",
        "model_2_preds = evaluate_and_pred(model_2, val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ5fpvMcdycF",
        "outputId": "06e899f6-8ed4-4887-8baa-6d807609ecde"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 8ms/step - loss: 0.8007 - accuracy: 0.7743\n",
            "Evaluation metrics: [0.8007400631904602, 0.7742782235145569]\n",
            "\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "Preds overview: [0. 1. 1. 0. 0. 1. 0. 1. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results\n",
        "model_2_results = calculate_results(val_labels, model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM3C55tFeLWA",
        "outputId": "3168e766-69dc-4f1b-c717-219ff54260a3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7742782152230971,\n",
              " 'precision': 0.7855294750736606,\n",
              " 'recall': 0.7742782152230971,\n",
              " 'f1-score': 0.7687856172080995}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5 - 1D Convolutional NN"
      ],
      "metadata": {
        "id": "O1M2k_X1eUT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model_5 = tf.keras.Sequential([\n",
        "    layers.Input(shape=(1,), dtype=tf.string),\n",
        "    text_vectorizer,\n",
        "    embedding,\n",
        "    layers.Conv1D(filters=64, \n",
        "                  kernel_size=5,\n",
        "                  strides=1,\n",
        "                  activation='relu',\n",
        "                  padding='same'),\n",
        "    layers.GlobalMaxPool1D(),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "], name='model_5_conv1d')\n",
        "\n",
        "# Compile the model\n",
        "model_5.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Check the summary\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTbMRMe5e0ct",
        "outputId": "70cbbdf7-1956-4d8e-bc33-e0c9971daa0b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_conv1d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 15, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_5_conv1d')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_vMVPwPfnxT",
        "outputId": "b90cf165-8902-419f-8b00-3c4f3080e943"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: exercise_model_logs/model_5_conv1d/20230326-195827\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 13ms/step - loss: 0.1442 - accuracy: 0.9537 - val_loss: 0.7724 - val_accuracy: 0.7927\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.0950 - accuracy: 0.9656 - val_loss: 0.8662 - val_accuracy: 0.7900\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.0752 - accuracy: 0.9726 - val_loss: 0.9673 - val_accuracy: 0.7822\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.0657 - accuracy: 0.9729 - val_loss: 1.0086 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.0599 - accuracy: 0.9756 - val_loss: 1.0886 - val_accuracy: 0.7795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate and predict\n",
        "model_5_preds = evaluate_and_pred(model_5, val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6EYPV6PgDEy",
        "outputId": "35b8c04f-5ea0-46b4-8ece-56d97a4c3aa8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 1.0886 - accuracy: 0.7795\n",
            "Evaluation metrics: [1.0885984897613525, 0.7795275449752808]\n",
            "\n",
            "24/24 [==============================] - 0s 4ms/step\n",
            "Preds overview: [0. 1. 1. 0. 0. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results\n",
        "model_5_results = calculate_results(val_labels, model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grg39bvMgS5e",
        "outputId": "ffdd7bce-c118-4cb5-fff2-ebfaf52fb1aa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7795275590551181,\n",
              " 'precision': 0.780644760213944,\n",
              " 'recall': 0.7795275590551181,\n",
              " 'f1-score': 0.7778858484546237}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2\n",
        "Retrain the baseline model with 10% of the training data. How does it perform to the Universal Sentence Encoder model with 10% of the training data?"
      ],
      "metadata": {
        "id": "Pa_jIgpsgbCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the right amount of data for the split\n",
        "train_10_percent_split = int(0.1 * len(train_sentences))\n",
        "\n",
        "# Recreate the 10% training data split\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
        "\n",
        "# Check the split\n",
        "print(f\"Length of base set: {len(train_sentences)}\")\n",
        "print(f\"Length of 10 percent set: {len(train_sentences_10_percent)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLJz0ot1hJ3V",
        "outputId": "9e81e3e6-d654-443c-a279-9de7c039de4f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of base set: 6851\n",
            "Length of 10 percent set: 685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreating the baseline model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create pipeline with tokenization\n",
        "model_0 = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to 10% dataset\n",
        "model_0.fit(train_sentences_10_percent, train_labels_10_percent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "Uk-dJe7KiXGo",
        "outputId": "1d284e38-5a27-42da-c324-d6e48a3cad2d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate and pred\n",
        "model_0_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Baseline model score: {model_0_score}\")\n",
        "\n",
        "model_0_preds = model_0.predict(val_sentences)\n",
        "model_0_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGAazKUajNmh",
        "outputId": "0649a74b-db1d-4c83-cbff-900c9f9e12db"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline model score: 0.7020997375328084\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 1, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results\n",
        "model_0_results = calculate_results(val_labels, model_0_preds)\n",
        "model_0_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pZBPB5Pjg8o",
        "outputId": "83d9a8c7-fff9-40c9-b6ca-c2446949f721"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7020997375328084,\n",
              " 'precision': 0.7599524002753854,\n",
              " 'recall': 0.7020997375328084,\n",
              " 'f1-score': 0.6736831571468213}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How did the model perform compared to USE model from `08` notebook?\n",
        "* The USE model trained on 10% of the data did get about 77,5%.\n",
        "* The retrained baseline model from `sklearn` with `MultinomialNB` classifier, also trained on about 70,2% accuracy.\n",
        "\n",
        "**This shows that the smaller the dataset, maybe using the pretrained model from TF Hub is a good idea to include in the experiment workflow.**\n"
      ],
      "metadata": {
        "id": "V7QfcqjHk2vh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3\n",
        "Try fine-tuning the TF Hub USE (`model_6`) by setting `training=True` when instentiating it as a Keras layer."
      ],
      "metadata": {
        "id": "eEbJYJ99kEDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the USE model used in 08"
      ],
      "metadata": {
        "id": "8JPrakWLl53h"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "klj5M_kfl-Pq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}