{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "v-sCQ2BUhcA5",
        "X-Qi_AsLpMT4",
        "0NbSYQcvBX1O",
        "7cRi2IR7ly3f"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone Project 2 - SkimLit\n",
        "\n",
        "The purpose of this notebook is to build a NLP model to make reading medical abstracts easier.\n",
        "\n",
        "The paper we're replicating (the source of the dataset we'll be using) is available here: https://arxiv.org/pdf/1710.06071.pdf\n",
        "\n",
        "And reading through the paper above, we'll see that the model architecture that they use to achieve their best results is available here: https://arxiv.org/pdf/1612.05251.pdf"
      ],
      "metadata": {
        "id": "fP9FeDlWXvu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confirm access to a GPU"
      ],
      "metadata": {
        "id": "v-sCQ2BUhcA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCB3hZtshopv",
        "outputId": "4579e7e7-b1a6-48e5-996d-a242ed600b7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-bb4f1bf1-9844-93fe-0885-cbd2c190c125)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data\n",
        "\n",
        "Since we'll be replicating the paper above (PubMed 200k RCT), let's download the dataset they used.\n",
        "\n",
        "We can do so from the authors GitHub: https://github.com/Franck-Dernoncourt/pubmed-rct\n"
      ],
      "metadata": {
        "id": "WvLHQZDghqCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz8gHrKXiFRW",
        "outputId": "e8943fa3-eed2-4b0a-c56f-91762efb1a6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 5), reused 5 (delta 5), pack-reused 25\u001b[K\n",
            "Unpacking objects: 100% (33/33), 177.08 MiB | 6.48 MiB/s, done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what files are in the PubMed_20k dataset\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs5d-G0IiNkm",
        "outputId": "76cdc3ff-ba14-445b-f6c6-f8c50036a375"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start our experiments using 20k dataset with numbers replaces by '@' sign\n",
        "data_dir = \"/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "prX4Wj8ritZD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check all of the filenames in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rtyJtHdj20-",
        "outputId": "5836dc27-3a8b-4c44-d006-98f970e5b978"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess data\n",
        "\n",
        "Now we've got some text data, it's time to become in with it. And one of the best ways to become one with the dataset is...\n",
        "\n",
        "> Visualize, visualize, visualize\n",
        "\n",
        "With that in mind, let's write a funciton to read in all of the lines of a target files."
      ],
      "metadata": {
        "id": "c6gviMRrkEJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to read the lines of a document\n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Reads filename (text filename) and returns the lines of text as a list.\n",
        "  \n",
        "  Args:\n",
        "    filename: a string containing the target filepath\n",
        "\n",
        "  Returns:\n",
        "    A list of strings with one string per line from the target filename.\n",
        "  \"\"\"\n",
        "\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "ECUVgir6k5Xz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's read in the training lines\n",
        "train_lines = get_lines(data_dir+'train.txt')\n",
        "train_lines[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmkvQoX5laDQ",
        "outputId": "5ca5c628-bb7c-4a0c-ce35-5d883d7c9f03"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KI-FZaNllsf",
        "outputId": "8bb2eb1e-b891-4ce8-d10c-261722ec8a0d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's think about how we want our data to look...\n",
        "\n",
        "How I think our data would be best represented...\n",
        "\n",
        "```\n",
        "[{'line number': 0,\n",
        "   'target': 'BACKGROUND',\n",
        "   'text': 'Emotional eating is associated with overeating and the development of obesity .\\n',\n",
        "   'total_lines': 11},\n",
        "   ...]\n",
        "```"
      ],
      "metadata": {
        "id": "wH4V1m_il7HT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write a function which turn each of our datasets into the above format so we can continue to prepare our data for modelling."
      ],
      "metadata": {
        "id": "tdmnz6Uc8qMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_linenumbers(filename):\n",
        "  \"\"\"\n",
        "  Returns a list of dictionaries of abstract line data. \n",
        "\n",
        "  Takes in filename, reads its contents and sorth through each line,\n",
        "  extracting things like the target label, the text of the sentence, \n",
        "  how many sentences are in the current abstract and what sencence number\n",
        "  the target line is.\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "  abstract_lines = \"\" # create an empty abstract\n",
        "  abstract_samples = [] # create an empty list of abstracts\n",
        "\n",
        "  for line in input_lines:\n",
        "\n",
        "    if line.startswith('###'): # check if the line is ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset the abstract string if the line is an ID line\n",
        "\n",
        "    elif line.isspace(): # check to see if the line is the new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split the lines into new lines\n",
        "\n",
        "       # Iterate through each lines in a single abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create and empty dictionary for each line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split the target label from text\n",
        "        line_data['target'] = target_text_split[0] # get target label\n",
        "        line_data['text'] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data['line_number'] = abstract_line_number # what number line does the line appear in the abstract\n",
        "        line_data['total_lines'] = len(abstract_line_split) - 1 # how many total lines are there in total abstract\n",
        "\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "    else: # if the above conditions are not met, the line contains labelled sentence\n",
        "      abstract_lines += line\n",
        "\n",
        "  return abstract_samples"
      ],
      "metadata": {
        "id": "RC-Ay5i-l29C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data from file and preprocess it\n",
        "%%time\n",
        "train_samples = preprocess_text_with_linenumbers(data_dir+'train.txt')\n",
        "val_samples = preprocess_text_with_linenumbers(data_dir+'dev.txt') # dev = validation\n",
        "test_samples = preprocess_text_with_linenumbers(data_dir+'test.txt')\n",
        "print(len(train_samples), len(val_samples), len(test_samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XddyFlkNA0JQ",
        "outputId": "118e3769-faab-466f-c9f0-265747beddef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180040 30212 30135\n",
            "CPU times: user 364 ms, sys: 92.2 ms, total: 456 ms\n",
            "Wall time: 455 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first abstract of training data\n",
        "train_samples[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOWg3Wl3BXaH",
        "outputId": "b9b03146-7d0b-4e22-8039-f2a7e7650c65"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'line_number': 10,\n",
              "  'total_lines': 11},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'line_number': 11,\n",
              "  'total_lines': 11},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 10},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 10},\n",
              " {'target': 'OBJECTIVE',\n",
              "  'text': 'the aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now as the data is in the format of list of dictionaries, let's turn it into a pandas DataFrame to further visualize it."
      ],
      "metadata": {
        "id": "ldMkxA5BCF54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "\n",
        "train_df.head(14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "ljema8FnBvBE",
        "outputId": "fbed9451-bb92-491e-9ab4-1cea8e36894a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target                                               text  \\\n",
              "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
              "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
              "2       METHODS  outcome measures included pain reduction and i...   \n",
              "3       METHODS  pain was assessed using the visual analog pain...   \n",
              "4       METHODS  secondary outcome measures included the wester...   \n",
              "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
              "6       RESULTS  there was a clinically relevant reduction in t...   \n",
              "7       RESULTS  the mean difference between treatment arms ( @...   \n",
              "8       RESULTS  further , there was a clinically relevant redu...   \n",
              "9       RESULTS  these differences remained significant at @ we...   \n",
              "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
              "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
              "12   BACKGROUND  emotional eating is associated with overeating...   \n",
              "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
              "\n",
              "    line_number  total_lines  \n",
              "0             0           11  \n",
              "1             1           11  \n",
              "2             2           11  \n",
              "3             3           11  \n",
              "4             4           11  \n",
              "5             5           11  \n",
              "6             6           11  \n",
              "7             7           11  \n",
              "8             8           11  \n",
              "9             9           11  \n",
              "10           10           11  \n",
              "11           11           11  \n",
              "12            0           10  \n",
              "13            1           10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18c79f60-1739-4fb3-9969-8deffcb1b100\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18c79f60-1739-4fb3-9969-8deffcb1b100')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18c79f60-1739-4fb3-9969-8deffcb1b100 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18c79f60-1739-4fb3-9969-8deffcb1b100');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of labels in training data\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG4OujRPCadg",
        "outputId": "a4ae95fe-ab9b-4ace-f733-813388cdc101"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the length of different lines\n",
        "train_df.total_lines.plot.hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "1WIYNSoGC2W9",
        "outputId": "20db9177-609c-4c65-a616-b7b94dbe80b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Frequency'>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get list of sentences"
      ],
      "metadata": {
        "id": "yfqZZJMzDCU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert abstrat text lines into lists\n",
        "train_sentences = train_df['text'].to_list()\n",
        "val_sentences = val_df['text'].to_list()\n",
        "test_sentences = test_df['text'].to_list()\n",
        "print(len(train_sentences), len(val_sentences), len(test_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vj06ICHDPDp",
        "outputId": "07ee1952-2dd1-4305-add3-2f999a7ef033"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180040 30212 30135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first lines of training sentences\n",
        "train_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF6bRa5KDiYQ",
        "outputId": "978daa03-c676-4c7a-d97f-ef12f9ca11f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make numeric labels "
      ],
      "metadata": {
        "id": "jSf_ASRfDsNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False) # we want a non-sparse matrix\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df['target'].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df['target'].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df['target'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# check what one-hot encoded labels look like\n",
        "train_labels_one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcqeUbd4EbHl",
        "outputId": "c55331ca-e29c-4400-f85d-f22e142272af"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label encoded labels"
      ],
      "metadata": {
        "id": "_oQZAkRYGxRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract labels ('target' columns) and encode them into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df['target'].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df['target'].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df['target'].to_numpy())\n",
        "\n",
        "# Check how the labels look like\n",
        "train_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXzUezN9HwH9",
        "outputId": "e9e24122-2d03-46fc-df6f-315b025ad79c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names and number of classes from LabelEncoder instance\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8zBX9leIV3a",
        "outputId": "b8138623-3e50-4b58-9e8c-5f86e2ea2bb5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Starting a series of modelling experiments\n",
        "\n",
        "As usual, we're going to be trying out a bunch of different models and seeing which one works best.\n",
        "\n",
        "And as always, we're goint to start with a baseline: TF-IDF Multinomial Naive-Bayes classifier."
      ],
      "metadata": {
        "id": "CBPk2dpjmvoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0: Getting a baseline"
      ],
      "metadata": {
        "id": "A87PxC9QoFbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "model_0 = Pipeline([\n",
        "    ('tf-idf', TfidfVectorizer()),\n",
        "    ('clf', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X=train_sentences,\n",
        "            y=train_labels_encoded)"
      ],
      "metadata": {
        "id": "lwN3QgZJJLR6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "030fa0e4-c2e8-4878-ddb6-d4b28af562c6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate baseline model on validation dataset\n",
        "model_0.score(X=val_sentences,\n",
        "              y=val_labels_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ29VYybozMv",
        "outputId": "c78ea43e-f3a6-406d-a0ec-2a62fba1b010"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions using baseline model\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIw4O_p3pB_Z",
        "outputId": "14f1682b-8c1f-442a-994f-994feaa643e2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, 2, 2, 2, 2, 2, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download helper function script\n",
        "In the previous module we wrote a function to compare preditciotns across different metrics and rather than reweiting it here, let's download it from our helper function script: https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "X-Qi_AsLpMT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sN7HpmOMpgrc",
        "outputId": "f3e6a1b9-62c6-4f09-8d45-35fd73ee04f4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-11 19:41:07--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: helper_functions.py\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-11 19:41:08 (98.3 MB/s) - helper_functions.py saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import calculate_results\n",
        "\n",
        "# Calculate baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXaVaazLpp4P",
        "outputId": "e3f53574-f493-4494-a543-4f0a049e5735"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869,\n",
              " 'f1': 0.6989250353450294}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing our text data for deep sequence models\n",
        "\n",
        "Before we start building deeper models, we've got to create vectorization and embedding layers."
      ],
      "metadata": {
        "id": "bchPNGRd3IIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "bGDXfBWJ3UHo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How long is each sentence on average?\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpe9JG4n3cdO",
        "outputId": "26e75aa4-2974-453c-f2dd-1e7b36597d62"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What's the distribution like?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "weF8q2fm4DcQ",
        "outputId": "26892053-42bd-44f7-aea1-03ac43bca4ea"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.6499e+04, 5.6664e+04, 5.2683e+04, 2.9050e+04, 1.3111e+04,\n",
              "        5.6610e+03, 3.0490e+03, 1.5190e+03, 8.0800e+02, 4.3200e+02,\n",
              "        2.2600e+02, 1.2800e+02, 7.7000e+01, 3.9000e+01, 3.0000e+01,\n",
              "        1.5000e+01, 9.0000e+00, 8.0000e+00, 4.0000e+00, 8.0000e+00,\n",
              "        7.0000e+00, 5.0000e+00, 1.0000e+00, 2.0000e+00, 3.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
              " array([  1.        ,  10.83333333,  20.66666667,  30.5       ,\n",
              "         40.33333333,  50.16666667,  60.        ,  69.83333333,\n",
              "         79.66666667,  89.5       ,  99.33333333, 109.16666667,\n",
              "        119.        , 128.83333333, 138.66666667, 148.5       ,\n",
              "        158.33333333, 168.16666667, 178.        , 187.83333333,\n",
              "        197.66666667, 207.5       , 217.33333333, 227.16666667,\n",
              "        237.        , 246.83333333, 256.66666667, 266.5       ,\n",
              "        276.33333333, 286.16666667, 296.        ]),\n",
              " <BarContainer object of 30 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How long of a sentence length covers 95% of the examples?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts6dYMe-4hXS",
        "outputId": "5fb27d3c-b65a-4a24-d6be-1b8c1732469f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Max sequence length in training set\n",
        "max(sent_lens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQKCvDef48vP",
        "outputId": "e4fae329-71da-4f1f-fe55-d18f0a70d4e4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create text vectorizer layer\n",
        "We want to get a layer that maps our text from words to numbers. Here's how it can be done..."
      ],
      "metadata": {
        "id": "jB_u9N4N5Uq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many words are in our vocab (taken directly from the paper)\n",
        "max_tokens = 68000"
      ],
      "metadata": {
        "id": "sQxUE_rN7gEw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create text vectorizer\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, # number of words in the vocabulary\n",
        "                                    output_sequence_length=output_seq_len) # desired output length of vectorized sequences"
      ],
      "metadata": {
        "id": "O5sVjG_O7mXu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "rtPBoRf08LLp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out text vectorizer on random sentences\n",
        "import random\n",
        "target_sequence = random.choice(train_sentences)\n",
        "print(f\"Base sentence: \\n{target_sequence}\\n\")\n",
        "print(f\"Length of text: \\n{len(target_sequence.split())}\\n\")\n",
        "print(f\"Vectorized sentence: \\n{text_vectorizer(target_sequence)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKNtYlDY8fX1",
        "outputId": "e0dd109e-ccbc-40f9-b116-80d464d4a8d9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base sentence: \n",
            "patients in group p received propofol in titrated doses to attain a burst suppression ratio of @ @ % on bispectral index ( bis ) monitor .\n",
            "\n",
            "Length of text: \n",
            "27\n",
            "\n",
            "Vectorized sentence: \n",
            "[  12    5   13   14   80  914    5 3147  321    6 8759    8 6555 1640\n",
            "  166    4   18 5855  203 2649 2477    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many words in our training vocabulary?\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocab: {len(rct_20k_text_vocab)}\")\n",
        "print(f\"Most common words in the vocab: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least common words in the vocab: {rct_20k_text_vocab[-5:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWePL6O_9foN",
        "outputId": "873ce90b-3d29-4d72-b347-ff4d0941c8eb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 64841\n",
            "Most common words in the vocab: ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least common words in the vocab: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w5WeTAo-cc3",
        "outputId": "080f537b-5287-4a7a-d6a6-1d0ab065f9c8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'text_vectorization',\n",
              " 'trainable': True,\n",
              " 'dtype': 'string',\n",
              " 'batch_input_shape': (None,),\n",
              " 'max_tokens': 68000,\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'split': 'whitespace',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'sparse': False,\n",
              " 'ragged': False,\n",
              " 'vocabulary': None,\n",
              " 'idf_weights': None,\n",
              " 'encoding': 'utf-8',\n",
              " 'vocabulary_size': 64841}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create custom text embeedding layer"
      ],
      "metadata": {
        "id": "0NbSYQcvBX1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create token embedding layer\n",
        "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab),\n",
        "                               output_dim=128, # different embedding sizes result in a drastical change of paremeter numbers to be trained\n",
        "                               mask_zero=True, # using masking to handle variable sequence lengths (and save some space)  \n",
        "                               name=\"token_embedding\")"
      ],
      "metadata": {
        "id": "PHOYfZWPBtmu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show an example embeding\n",
        "print(f\"Sentence before vectorization: \\n{target_sequence}\\n\")\n",
        "print(f\"Sentence after vectorization: \\n{text_vectorizer(target_sequence)}\\n\")\n",
        "print(f\"Sentence after embedding: \\n{token_embed(text_vectorizer(target_sequence))}\\n\")\n",
        "print(f\"Embedded sentence shape: \\n{token_embed(text_vectorizer(target_sequence)).shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTkNt4TIIKuQ",
        "outputId": "c069d3b9-f2e7-4b6a-e43b-0eae01699d5a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization: \n",
            "patients in group p received propofol in titrated doses to attain a burst suppression ratio of @ @ % on bispectral index ( bis ) monitor .\n",
            "\n",
            "Sentence after vectorization: \n",
            "[  12    5   13   14   80  914    5 3147  321    6 8759    8 6555 1640\n",
            "  166    4   18 5855  203 2649 2477    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "\n",
            "Sentence after embedding: \n",
            "[[ 0.00553596  0.03823993 -0.01631581 ...  0.0411532  -0.04543258\n",
            "   0.021096  ]\n",
            " [-0.00332319 -0.02331462  0.03340169 ...  0.01170063 -0.04469157\n",
            "   0.04967124]\n",
            " [-0.01051597 -0.04848187 -0.04012183 ...  0.04393044  0.02517278\n",
            "  -0.02397703]\n",
            " ...\n",
            " [-0.01913159  0.04033406  0.00791135 ... -0.03959699  0.00110511\n",
            "  -0.03298216]\n",
            " [-0.01913159  0.04033406  0.00791135 ... -0.03959699  0.00110511\n",
            "  -0.03298216]\n",
            " [-0.01913159  0.04033406  0.00791135 ... -0.03959699  0.00110511\n",
            "  -0.03298216]]\n",
            "\n",
            "Embedded sentence shape: \n",
            "(55, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating datasets (making sure our data loads as fast as possible)\n",
        "We're going to setup od data to run as fast as possible with the Tensorflow `tf.data` API, many of the steps are discussed at length in these two resources:\n",
        "* https://www.tensorflow.org/guide/data_performance\n",
        "* https://www.tensorflow.org/guide/data"
      ],
      "metadata": {
        "id": "7cRi2IR7ly3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uor9BvTqm2fO",
        "outputId": "bc54e4b8-c509-466b-89f7-2853e26b2abb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the TensorSliceDatasets and turn them into prefeteched datasets\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # no shuffling but the data order is important in this task!\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQwHgnBbn00p",
        "outputId": "97798e8a-e9b3-4f58-da8d-fedea7e9a535"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: Conv1D with token embeddings"
      ],
      "metadata": {
        "id": "P-wG8CmerxVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 1D conv model to process sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = text_vectorizer(inputs) # vectorizing the text (string -> numbers)\n",
        "token_embeddings = token_embed(text_vectors) # create embeddings\n",
        "x = layers.Conv1D(filters=64, \n",
        "                  kernel_size=5,\n",
        "                  padding='same',\n",
        "                  activation='relu')(token_embeddings)\n",
        "x = layers.GlobalMaxPooling1D()(x) # condense the output of feature vector\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGKJWD4VpWCc",
        "outputId": "8ab54021-f963-4151-fe1c-525044d97501"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 55)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " token_embedding (Embedding)  (None, 55, 128)          8299648   \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 55, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,340,997\n",
            "Trainable params: 8,340,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_model_1 = model_1.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1*len(train_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1*len(valid_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geEbrBK2rENi",
        "outputId": "2ec06e40-9efd-4d29-b168-d1485bd57970"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 27s 45ms/step - loss: 0.5740 - accuracy: 0.7952 - val_loss: 0.5558 - val_accuracy: 0.8002\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 7s 12ms/step - loss: 0.4803 - accuracy: 0.8279 - val_loss: 0.5554 - val_accuracy: 0.7975\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 5s 9ms/step - loss: 0.4587 - accuracy: 0.8352 - val_loss: 0.5483 - val_accuracy: 0.7916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on whole validation dataset\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM_LYt8Wr2kF",
        "outputId": "39af594e-6b05-4a0d-83d3-12c948d25966"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 4s 4ms/step - loss: 0.5549 - accuracy: 0.7933\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5549198389053345, 0.7933271527290344]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions (and our model predicts probability per class)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLJCaCKjsbGq",
        "outputId": "74782f99-165c-4f05-dab0-0213158c08f2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 2s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.47624952e-01, 1.62133470e-01, 6.93623647e-02, 2.88630635e-01,\n",
              "        3.22486572e-02],\n",
              "       [4.59049642e-01, 2.62744904e-01, 1.42792296e-02, 2.53385067e-01,\n",
              "        1.05412286e-02],\n",
              "       [1.40319154e-01, 4.66136308e-03, 1.28256157e-03, 8.53706479e-01,\n",
              "        3.04405366e-05],\n",
              "       [1.38175474e-05, 5.48185548e-04, 9.81299222e-01, 1.01403693e-05,\n",
              "        1.81285869e-02],\n",
              "       [1.03425572e-03, 5.76691367e-02, 3.30060154e-01, 6.59630459e-04,\n",
              "        6.10576868e-01],\n",
              "       [1.97189581e-02, 3.08167655e-02, 5.45834482e-01, 8.39095563e-03,\n",
              "        3.95238787e-01],\n",
              "       [4.52686596e-04, 3.90983606e-03, 2.71619827e-01, 1.95834102e-04,\n",
              "        7.23821759e-01],\n",
              "       [2.53254715e-02, 2.88297497e-02, 6.22293353e-01, 1.32786101e-02,\n",
              "        3.10272813e-01],\n",
              "       [3.00541926e-13, 1.67095759e-08, 1.23590510e-07, 1.05442205e-13,\n",
              "        9.99999881e-01],\n",
              "       [8.17454141e-03, 7.14450181e-01, 3.80041115e-02, 1.36594027e-02,\n",
              "        2.25711837e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilites to classes\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
        "model_1_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZniDFrBJsoXA",
        "outputId": "e706555b-0789-407d-fa30-a243005dff91"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 3, 2, 4, 2, 4, 2, 4, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foKhmoOos_Tu",
        "outputId": "d0a9dbb3-91c4-4be0-dc73-3fc72b9ddab4"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.8560836753608,\n",
              " 'precision': 0.785528758689063,\n",
              " 'recall': 0.7885608367536079,\n",
              " 'f1': 0.7863194699256897}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCcJUbJ5tLpl",
        "outputId": "01186fe2-2e7d-4e98-a5fa-85cd117e21c2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869,\n",
              " 'f1': 0.6989250353450294}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: Feature Extraction with pretrained token embeddings\n",
        "Now let's use pretrained word embeddings from TF Hub, more specifically the Universal Sentence Encoder (so USE in short): https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "\n",
        "The paper was originally created on GloVe embeddings, however we're going to stick with the lastest USE pretrained model."
      ],
      "metadata": {
        "id": "L7c7DbjLufVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained TF Hub USE \n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name='universal_sentence_encoder')"
      ],
      "metadata": {
        "id": "uaKlo6fjuivw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our pretrained embedding on random sentence\n",
        "random_train_sentence = random.choice(train_sentences)\n",
        "print(f\"Base sentence: \\n{random_train_sentence}\\n\")\n",
        "print(f\"Embedded sentence: \\n{tf_hub_embedding_layer([random_train_sentence])[0][:30]}\\n\")\n",
        "print(f\"Length of sentence embedding: {len(tf_hub_embedding_layer([random_train_sentence])[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKrPs1jF0Clq",
        "outputId": "40929229-ef11-4c80-d8f3-6d43d6d75701"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base sentence: \n",
            "the overall response rate was the primary endpoint .\n",
            "\n",
            "Embedded sentence: \n",
            "[ 0.00438316 -0.04103959 -0.05965524  0.01007693  0.01876203  0.00842769\n",
            "  0.01633962 -0.04815318  0.06939602  0.02401046 -0.03357402  0.02270431\n",
            " -0.05281222 -0.05101882 -0.01794758  0.04085029  0.07702652  0.00301012\n",
            "  0.03566603  0.04934152 -0.07894101  0.03164165 -0.00878052  0.06752303\n",
            " -0.01287219  0.01033381 -0.00200688  0.01868295 -0.00336235 -0.00401993]\n",
            "\n",
            "Length of sentence embedding: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building and fitting an NLP feature extraction model using a pretrained embeddings from TF Hub"
      ],
      "metadata": {
        "id": "aklxNMez0e-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature extraction model using TF Hub layer\n",
        "inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize and embed text of each sequence\n",
        "x = layers.Dense(128, activation='relu')(pretrained_embedding)\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, outputs, name='model_2_USE_feature_extractor')\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MfKa7cri7xEP"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of model_2\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDBdkoGg9NVP",
        "outputId": "be488767-5011-4319-a91a-fcdc7ab26a43"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_USE_feature_extractor\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None,)]                 0         \n",
            "                                                                 \n",
            " universal_sentence_encoder   (None, 512)              256797824 \n",
            " (KerasLayer)                                                    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model_2\n",
        "history_model_2 = model_2.fit(train_dataset,\n",
        "                              epochs=3,\n",
        "                              steps_per_epoch=int(0.1*len(train_dataset)),\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1*len(valid_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G69r6D049RPB",
        "outputId": "6f37ef2c-1896-4b29-d044-c74ef2aaab07"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 11s 15ms/step - loss: 0.9159 - accuracy: 0.6528 - val_loss: 0.7960 - val_accuracy: 0.6915\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.7675 - accuracy: 0.7028 - val_loss: 0.7542 - val_accuracy: 0.7035\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 7s 12ms/step - loss: 0.7500 - accuracy: 0.7138 - val_loss: 0.7369 - val_accuracy: 0.7121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate it on the whole dataset\n",
        "model_2.evaluate(valid_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rWDe_1J-KUY",
        "outputId": "a5b8887a-613d-4d71-ef30-de0f84f00e5d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 10s 11ms/step - loss: 0.7386 - accuracy: 0.7147\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7386206984519958, 0.7147160172462463]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax54eiBdBM2v",
        "outputId": "f82d25b6-9d80-4953-f5f6-f5dbe30195c3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 9s 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.31452245e-01, 3.69922638e-01, 2.79375026e-03, 1.86825648e-01,\n",
              "        9.00576636e-03],\n",
              "       [3.30631554e-01, 5.03941417e-01, 5.49761020e-03, 1.55881613e-01,\n",
              "        4.04786924e-03],\n",
              "       [2.28734016e-01, 1.15787707e-01, 1.85066201e-02, 6.00496650e-01,\n",
              "        3.64750214e-02],\n",
              "       [1.32880630e-02, 4.45586741e-02, 8.26767325e-01, 7.53576029e-03,\n",
              "        1.07850097e-01],\n",
              "       [2.93702260e-02, 2.55644977e-01, 2.25252718e-01, 1.35408165e-02,\n",
              "        4.76191252e-01],\n",
              "       [9.52654053e-04, 2.29271501e-03, 6.59293950e-01, 1.21389166e-04,\n",
              "        3.37339222e-01],\n",
              "       [2.12752912e-03, 3.21246265e-03, 6.14908695e-01, 1.34611677e-03,\n",
              "        3.78405213e-01],\n",
              "       [4.22384357e-03, 2.54845526e-02, 4.29121584e-01, 1.02749781e-03,\n",
              "        5.40142536e-01],\n",
              "       [7.24970829e-04, 5.81609504e-03, 2.23664753e-02, 1.08805369e-03,\n",
              "        9.70004439e-01],\n",
              "       [1.18398383e-01, 7.15287864e-01, 2.81567723e-02, 7.58997425e-02,\n",
              "        6.22572824e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the prediction probabilities\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEVCZcw4BmNL",
        "outputId": "8a7e0bf6-33a4-4c8a-ca44-278505bd8edc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 1, 3, 2, 4, 2, 2, 4, 4, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results\n",
        "model_2_results = calculate_results(val_labels_encoded, model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F4JCAleB30v",
        "outputId": "903a43e3-3abe-4815-d290-1e6f9eb07809"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 71.47160068846816,\n",
              " 'precision': 0.7149096756602614,\n",
              " 'recall': 0.7147160068846816,\n",
              " 'f1': 0.7117223827755915}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XNbwamMB_JU",
        "outputId": "65a62a5a-b570-4f66-e139-5159d8e30363"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869,\n",
              " 'f1': 0.6989250353450294}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: Conv1D with character embeddings\n",
        "The paper which we're replicating states they used a combination of token and character-level embeddings.\n",
        "\n",
        "Previously we've token-level embeddings but we'll need to do similar steps for charecters if we want to use char-level embeddings."
      ],
      "metadata": {
        "id": "UH9OVbL6CGZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a character-level tokenizer"
      ],
      "metadata": {
        "id": "VaFL8j6qhqOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUcu39kKjEFB",
        "outputId": "df37a7cd-0b81-4c90-d760-7ab4ebe56107"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "# Text splitting non character-level sequence into characters\n",
        "split_chars(random_train_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "jfGsisgAjGSn",
        "outputId": "19e97d39-37f8-4eb2-ab7e-38307eb93f4b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t h e   o v e r a l l   r e s p o n s e   r a t e   w a s   t h e   p r i m a r y   e n d p o i n t   .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split sequence-level data splits into character-level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "print(train_chars[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFo32U8BjZRy",
        "outputId": "92a3cc4e-c4c9-434f-e442-27b912758e72"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What's the average character length?\n",
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LzY1SQEkaN-",
        "outputId": "4a27951b-a3a4-496a-efd2-d60fc60e285f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.3662574983337"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of our sequences on character level\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_lens, bins=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "dGHjvrO5k1ho",
        "outputId": "782eb7fa-2879-4109-af0b-db926248c55e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.2108e+04, 7.0583e+04, 5.3952e+04, 2.2391e+04, 7.4540e+03,\n",
              "        2.2350e+03, 8.0200e+02, 2.8700e+02, 1.1800e+02, 4.9000e+01,\n",
              "        2.9000e+01, 1.3000e+01, 8.0000e+00, 5.0000e+00, 1.0000e+00,\n",
              "        2.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
              " array([1.00000e+00, 7.02500e+01, 1.39500e+02, 2.08750e+02, 2.78000e+02,\n",
              "        3.47250e+02, 4.16500e+02, 4.85750e+02, 5.55000e+02, 6.24250e+02,\n",
              "        6.93500e+02, 7.62750e+02, 8.32000e+02, 9.01250e+02, 9.70500e+02,\n",
              "        1.03975e+03, 1.10900e+03, 1.17825e+03, 1.24750e+03, 1.31675e+03,\n",
              "        1.38600e+03]),\n",
              " <BarContainer object of 20 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find what character length covers 95% of the sequences\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHTM27LElEU6",
        "outputId": "f015f81e-6e20-459b-be34-96e5c71509c9"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all keyboard characters\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet, len(alphabet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOSsYnC0lWyn",
        "outputId": "6e15b016-6248-429d-c7af-49d95f27cfc9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~', 68)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char-level token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 # add 2 for space and OOV token (OOV -> out of vocabulary, '[UNK]')\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    standardize=None, # None -> punctuation will be left\n",
        "                                    name='char_vectorizer')"
      ],
      "metadata": {
        "id": "uRW2N3HtmB0r"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt character vectorizer to training characters\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "id": "nk6AXK4Pmuqn"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check character vocab stats\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of different chars: {len(char_vocab)}\")\n",
        "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
        "print(f\"5 least common characters: {char_vocab[-5:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5US38Hlm19y",
        "outputId": "b1d2d4dc-0897-4636-866f-c46ec802da06"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different chars: 57\n",
            "5 most common characters: ['', '[UNK]', 'e', 't', 'i']\n",
            "5 least common characters: ['|', '\"', ']', '\\\\', '[']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test character vectorizer\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text: \\n{random_train_chars}\\n\")\n",
        "print(f\"Length of random_train_chars: \\n{len(random_train_chars.split())}\\n\")\n",
        "vecorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"Vectorized, charified text: \\n{vecorized_chars}\")\n",
        "print(f\"Length of vectorized random_train_chars: \\n{len(vecorized_chars[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RNmZ8wMnLkJ",
        "outputId": "aadcb3e1-451a-41a8-af0c-6855c483c317"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text: \n",
            "t r e a d m i l l   t e s t i n g   w a s   p e r f o r m e d   i n   p a d   s u b j e c t s   t o   a s s e s s   m w t   .\n",
            "\n",
            "Length of random_train_chars: \n",
            "53\n",
            "\n",
            "Vectorized, charified text: \n",
            "[[ 3  8  2  5 10 15  4 12 12  3  2  9  3  4  6 18 21  5  9 14  2  8 17  7\n",
            "   8 15  2 10  4  6 14  5 10  9 16 23 37  2 11  3  9  3  7  5  9  9  2  9\n",
            "   9 15 21  3 25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]]\n",
            "Length of vectorized random_train_chars: \n",
            "290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating character-level embedding"
      ],
      "metadata": {
        "id": "YPl6wK51n-VN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char embedding layer\n",
        "char_embed = layers.Embedding(input_dim=len(char_vocab), # number of different characters\n",
        "                              output_dim=25, # size of the char embedding in the paper\n",
        "                              mask_zero=True,\n",
        "                              name='char_embed')"
      ],
      "metadata": {
        "id": "F_R9XBEwpfZs"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out char embedding layer\n",
        "print(f\"Charified text: \\n{random_train_chars}\\n\")\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "print(f\"Embedded, vectorizer and charified text: \\n{char_embed_example}\\n\")\n",
        "print(f\"Character embedding shape: \\n{char_embed_example.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHber1nIqFPD",
        "outputId": "cb3324ec-5aaa-4ea6-d403-109e320a5837"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text: \n",
            "t r e a d m i l l   t e s t i n g   w a s   p e r f o r m e d   i n   p a d   s u b j e c t s   t o   a s s e s s   m w t   .\n",
            "\n",
            "Embedded, vectorizer and charified text: \n",
            "[[[ 0.02913319  0.02431573 -0.03385228 ... -0.04077995  0.03876371\n",
            "   -0.01879939]\n",
            "  [-0.00340668 -0.02662643  0.02571115 ... -0.03857953  0.01317171\n",
            "   -0.02530519]\n",
            "  [-0.04396278  0.03122761  0.03287332 ... -0.02563853  0.01909567\n",
            "   -0.04254965]\n",
            "  ...\n",
            "  [-0.01600679 -0.00558303  0.04500714 ...  0.03262761 -0.03068377\n",
            "    0.02237208]\n",
            "  [-0.01600679 -0.00558303  0.04500714 ...  0.03262761 -0.03068377\n",
            "    0.02237208]\n",
            "  [-0.01600679 -0.00558303  0.04500714 ...  0.03262761 -0.03068377\n",
            "    0.02237208]]]\n",
            "\n",
            "Character embedding shape: \n",
            "(1, 290, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Conv1D model to fit on character embeddings"
      ],
      "metadata": {
        "id": "B5IO0s1c0SrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 3 - Conv1D with char level embedding\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "x = layers.Conv1D(filters=64,\n",
        "                  kernel_size=10,\n",
        "                  padding='same',\n",
        "                  activation='relu')(char_embeddings)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create a model\n",
        "model_3 = tf.keras.Model(inputs, \n",
        "                         outputs, \n",
        "                         name='model_3_conv1D_char_embeddings')\n",
        "\n",
        "# Check the summary\n",
        "model_3.summary()\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBMmjftaqqoL",
        "outputId": "1813cf2a-e567-4dae-e6c6-96e2d838368a"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_conv1D_char_embeddings\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " char_vectorizer (TextVector  (None, 290)              0         \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " char_embed (Embedding)      (None, 290, 25)           1425      \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 290, 64)           16064     \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,814\n",
            "Trainable params: 17,814\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char-lvel datasets\n",
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "train_char_dataset"
      ],
      "metadata": {
        "id": "44hXJGHJr_lZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b7fef0-d994-4dc8-ce54-76b1d0372d7e"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model on chars only\n",
        "model_3_history = model_3.fit(train_char_dataset,\n",
        "                              steps_per_epoch=int(0.1*len(train_char_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_dataset,\n",
        "                              validation_steps=int(0.1*len(val_char_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfXwo-Fo4Uof",
        "outputId": "fbaeda2a-771a-47d6-c464-e1bdb0dcd20a"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 7s 9ms/step - loss: 1.0785 - accuracy: 0.5831 - val_loss: 0.8599 - val_accuracy: 0.6729\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 3s 5ms/step - loss: 0.8277 - accuracy: 0.6766 - val_loss: 0.7663 - val_accuracy: 0.7081\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 3s 6ms/step - loss: 0.7553 - accuracy: 0.7118 - val_loss: 0.7038 - val_accuracy: 0.7301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model_3.evaluate(val_char_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3Xgp_dL4qIU",
        "outputId": "b2d65726-a253-41bd-d779-d202a0d5d46a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 4s 4ms/step - loss: 0.7185 - accuracy: 0.7268\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7185311317443848, 0.7267642021179199]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with character level only\n",
        "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
        "print(f\"Preds shape: \\n{model_3_pred_probs.shape}\")\n",
        "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
        "print(f\"Exemplary preds: \\n{model_3_preds[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jQVyaXp5d4a",
        "outputId": "adb1d63b-fb8e-4b23-a80a-32705158d213"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 2s 2ms/step\n",
            "Preds shape: \n",
            "(30212, 5)\n",
            "Exemplary preds: \n",
            "[1 1 3 2 2 2 2 1 4 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the results for Conv1D chars only\n",
        "model_3_results = calculate_results(val_labels_encoded,\n",
        "                                    model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Oc2DyfM6Gyq",
        "outputId": "2a38b387-93b8-4604-f211-245a52fc31e6"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.67641996557659,\n",
              " 'precision': 0.7281138925153591,\n",
              " 'recall': 0.7267641996557659,\n",
              " 'f1': 0.7204982220642929}"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uADdHbzB6pmj",
        "outputId": "f837d7eb-19fa-401f-d0a2-823fd43daad4"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869,\n",
              " 'f1': 0.6989250353450294}"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4: Combining pretrained token embeddings + character embeddings (hybrid style model)\n",
        "\n",
        "1. Create a token-level embedding model (similar `model_1`)\n",
        "2. Create a character-level embedding model (simiar to `model_3` but with slight adjustment)\n",
        "3. Combine 1 & 2 with a concatenate (`layers.Concatenate`)\n",
        "4. Build a series of output layers on top of 3 (simiar to Figure 1 and section 4.2 of paper https://arxiv.org/pdf/1612.05251.pdf)\n",
        "5. Construct a model which takes token and character-level sequences as inputs and produces sequence label probaiblities as output."
      ],
      "metadata": {
        "id": "Z_biZ8lo6pHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup token inputs/model\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name='token_input')\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation='relu')(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_outputs)\n",
        "\n",
        "# 2. Setup char inputs/model\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name='char_input')\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings) # bi-LSTM shown in Figure 1 of paper\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Concatenate token and char inputs (create hybrid token embedding)\n",
        "token_char_concat = layers.Concatenate(name='token_char_hybrid')([token_model.output, \n",
        "                                                                  char_model.output])\n",
        "\n",
        "# 4. Create output layers - adding in Dropout, discussed section 4.2 of paper\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "combined_dense = layers.Dense(128, activation='relu')(combined_dropout)\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(final_dropout)\n",
        "\n",
        "# 5. Construct model with char and token inputs\n",
        "model_4 = tf.keras.Model(inputs=[token_model.input,\n",
        "                                 char_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name='token_char_embeddigns')"
      ],
      "metadata": {
        "id": "_Rl4oybtC-MK"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the summary\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx9WcKTVGorJ",
        "outputId": "fca81bab-046f-4cb5-b95e-0a0ac47c9d40"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"token_char_embeddigns\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " char_input (InputLayer)        [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " token_input (InputLayer)       [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " char_vectorizer (TextVectoriza  (None, 290)         0           ['char_input[0][0]']             \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " universal_sentence_encoder (Ke  (None, 512)         256797824   ['token_input[0][0]']            \n",
            " rasLayer)                                                                                        \n",
            "                                                                                                  \n",
            " char_embed (Embedding)         (None, 290, 25)      1425        ['char_vectorizer[3][0]']        \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 128)          65664       ['universal_sentence_encoder[2][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 48)          9600        ['char_embed[3][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " token_char_hybrid (Concatenate  (None, 176)         0           ['dense_10[0][0]',               \n",
            " )                                                                'bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 176)          0           ['token_char_hybrid[0][0]']      \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 128)          22656       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 128)          0           ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 5)            645         ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 256,897,814\n",
            "Trainable params: 99,990\n",
            "Non-trainable params: 256,797,824\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v9QLBaN2HhRd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}